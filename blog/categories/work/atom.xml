<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Work | Blog of Ditsing]]></title>
  <link href="http://www.ditsing.com/blog/categories/work/atom.xml" rel="self"/>
  <link href="http://www.ditsing.com/"/>
  <updated>2014-09-24T15:57:59+10:00</updated>
  <id>http://www.ditsing.com/</id>
  <author>
    <name><![CDATA[ditsing]]></name>
    <email><![CDATA[ditsing@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[记一个工作中遇到的问题]]></title>
    <link href="http://www.ditsing.com/blog/2014/09/23/ji-yi-ge-gong-zuo-zhong-yu-dao-de-wen-ti/"/>
    <updated>2014-09-23T21:30:47+10:00</updated>
    <id>http://www.ditsing.com/blog/2014/09/23/ji-yi-ge-gong-zuo-zhong-yu-dao-de-wen-ti</id>
    <content type="html"><![CDATA[<p>一年没有写博客了，写一个我今年在工作中遇到的问题吧。</p>

<blockquote><p>首先有一个字符串集合<code>A</code>（母串集），<code>A</code>中大概有1.6x10<sup>10</sup>个字符串。这些字符串大部分都比较短，长度小于100。最长的字符串有2<sup>16</sup>个字符。</p>

<p>还有一个比较小的字符串集合<code>B</code>（子串集）。<code>B</code>里的每个字符串都是<code>A</code>里某个字符串的前缀，共有2.4x10<sup>7</sup>个前缀。<code>B</code>中的每个字符串都与一个非负整数相关联。</p>

<p>现在对于<code>A</code>中的每个字符串<code>a_i</code>，求一个整数。这个整数等于<code>B</code>中所有<code>a_i</code>的前缀所对应的整数的最大值。</p></blockquote>

<p>（之前已经听我白话过这个问题的同学们：是的，问题规模又扩大了。）</p>

<p>背景：<code>A</code>是数据的key集合，<code>B</code>是用户的删除数据请求，删除被匹配的key和它对应的数据。因此，最后<code>A</code>中被匹配到的字符串不会特别多，大约是<code>B</code>的大小的若干倍。可以认为远小于100倍。</p>

<!--more-->


<p>看到这个问题的规模，我们就知道只能跑在一台机器上的算法是不行的。必须设计一个能并行地跑在许多台机器上的算法。</p>

<p>这个问题的规模如果小一点，就相当容易解决。例如，如果<code>B</code>中的字符串少一点，少到2.4x10<sup>4</sup>个。我们就可以把<code>B</code>做成一个Trie直接扔到内存里。准备若干台机器，每台机器都复制一份。给每台机器分配<code>A</code>的一段，各自扫描就好了。这样的复杂度是<code>length(sigma A + sigma B)</code>的。可能会比较占内存，但是现在内存都是白菜价了， who cares。</p>

<p>如果<code>B</code>再大一点点，大到2.4x10<sup>6</sup>，问题也不是那么难。我们可以：</p>

<ol>
<li>把<code>B</code>分成一百份，每次用上述方法处理一份，处理一百次；</li>
<li>或者，找一份可以放在硬盘上的Trie实现（假设能找得到）。Trie的每次查询只用到整个Trie的很小一部分。实现时只需要把查询时能访问到的部分装载到内存里，访问不到的swap到硬盘上就可以了。如果性能不足，还可以把4个byte压缩成一个long，既减少硬盘读写又减少空间浪费。</li>
<li>再或者两种方案结合，把<code>B</code>分成10份，每次用硬盘Trie处理一份。即使用最烂的（我的）实现，Trie文件的大小也不过几十G，可以接受。</li>
</ol>


<p>但是拆分<code>B</code>的方案不能把<code>B</code>拆成太多份。因为每拆一份<code>B</code>都要把<code>A</code>复制一份，也就意味着多一份的数据读写。不幸的是我司的storage层对许多个并行读者的支持并不好，过多读者会导致大家都读得更慢。<code>B</code>如果再大，拆分的方法就不好用了。</p>

<p>大家有什么想法？我的答案在下面，不要偷看哦。</p>

<br/>


<br/>


<br/>


<hr />

<center>答案分割线</center>


<hr />

<br/>


<br/>


<br/>


<br/>


<p>解决方案其实很简单，相信大家也都想到了：hash。</p>

<p>对集合<code>B</code>里的每一个子串，hash它长度为2的整数次幂的<strong>最长前缀</strong>。如果一个串的长度为19，就hash前16个字符；如果长度是32，就hash所有字符。这样我们得到了2.4x10<sup>7</sup>个long，大约占192M内存（我是不是算错了&hellip;.对这个数字没什么信心）。</p>

<p>把这些hash值扔到一个数组<code>b_hash_set</code>里，排序之。</p>

<p>对于集合<code>A</code>里的每个母串，hash它的<strong>每个</strong>长度为2的整数次幂的<strong>前缀</strong>。对于每个字符串<code>a_i</code>，我们会得到<code>log(length(a_i))</code>个数字。称这些hash值的集合为<code>a_hash_set</code>。
如果<code>a_hash_set</code>和<code>b_hash_set</code>中的某一对数字<code>a_hash</code>和<code>b_hash</code>相等，他们分别对应的母串和子串才<strong>有可能</strong>前缀匹配。就不证明了，结论非常明显。</p>

<p>这时再暴力匹配有可能的字符串对，运行时间就完全可以接受了。</p>

<p>一个小优化：在生成<code>a_hash_set</code>的一个值的时候，可以直接在<code>b_hash_set</code>里二分查找这个值。如果不存在，就不用把它放到<code>a_hash_set</code>里了。这样可以显著减小<code>a_hash_set</code>（以及和它关联的数据）的体积。在实践中，优化后<code>a_hash_set</code>的体积缩小了三百倍。</p>

<p>如何找到所有相等的<code>a_hash</code>和<code>b_hash</code>对？把它们扔到一起sort就可以了。<code>a_hash_set</code>的体积可能会特别大，但是我们也有分布式排序算法嘛。</p>

<h3>后话</h3>

<p>上次在群里跟大家讨论的时候，范神@ronaflx提到，他们判断整个字符串相等的时候都会先算hash，然后暴力匹配。我当时还觉得，暴力就暴力吧，hash能有什么作用？仔细一想，使用hash，子串和母串都只需要扫描一遍；而且hash本身的体积比字符串小很多，比较容易传递。在这里顺便感谢范神给我普及字符串匹配基础知识。</p>

<p>但是hash只能判断相等（严格来说，只能确定不等），不能判断前缀。一个常见的workaround是把母串的所有前缀都hash了，再和子串的hash比。这样的方案在母串都不长的情况下很适用。但是在这个问题上，这样做会在时间复杂度上乘一个一百左右的常数。要减小常数，只处理2的整数次幂也是常见workaround：牺牲部分精度（子串的一部分被忽略了），但是可以把常数从100减少到6。</p>

<p>最后，欢迎大家提出更好的方法来打脸！</p>

<h3>吐槽</h3>

<p>Java的TreeSet存2.4x10<sup>7</sup>个数，居然要占用10多G内存！你丫是暴力数组实现的Trie吧！</p>

<p>下次给自己的service设计功能的时候，一定要先想想到底能不能高效实现。堂堂大Google，若干M个请求都处理不好，混不混了！</p>

<h3>感慨</h3>

<p>本文就是我今年工作最大的成绩了。进入Google一年，蹉跎一年，一事无成，Todo List 基本没有刷，能力进步为零。</p>

<p>逆水行舟，不进则退。与君共勉！</p>
]]></content>
  </entry>
  
</feed>
